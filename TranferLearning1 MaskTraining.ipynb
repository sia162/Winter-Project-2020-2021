{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TranferLearning1 MaskTraining.ipynb","provenance":[],"mount_file_id":"1491JkYdJazBzAypgckdgQP4SlXqeUN6Q","authorship_tag":"ABX9TyMEcT6lQW79pGEy4uww+dsH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"HXUr_qoRlPVO"},"source":["import numpy as np\r\n","import os\r\n","import matplotlib.pyplot as plt\r\n","from imutils import paths #to access dataset\r\n","\r\n","from tensorflow.keras.applications import MobileNetV2 #importing architecture\r\n","from tensorflow.keras.layers import AveragePooling2D\r\n","from tensorflow.keras.layers import Dropout\r\n","from tensorflow.keras.layers import Flatten\r\n","from tensorflow.keras.layers import Dense\r\n","from tensorflow.keras.layers import Input\r\n","from tensorflow.keras.models import Model\r\n","from tensorflow.keras.optimizers import Adam \r\n","from tensorflow.keras.applications.mobilenet_v2 import preprocess_input \r\n","\r\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator #to preprocess image by generating more images\r\n","from tensorflow.keras.preprocessing.image import img_to_array #to convert image to array\r\n","from tensorflow.keras.preprocessing.image import load_img\r\n","from tensorflow.keras.utils import to_categorical\r\n","from sklearn.preprocessing import LabelBinarizer #to make model understand the 2 sets of images\r\n","from sklearn.model_selection import train_test_split\r\n","from sklearn.metrics import classification_report"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"53zqS9qtN40j"},"source":["dataset = '/content/drive/MyDrive/dataset'\r\n","imagePaths  = list(paths.list_images(dataset)) #this will make list of the all images"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nWI1-nwoQyMd"},"source":["imagePaths"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FirQZAbHhaX2","executionInfo":{"status":"ok","timestamp":1612091711492,"user_tz":-330,"elapsed":1074,"user":{"displayName":"Siya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOgjn8zFSPn3wjONE5ghQ8g-5T-vg_1E4Zs9ZBOA=s64","userId":"12174409055975084288"}},"outputId":"5feba860-062b-4439-f81b-70a4d517afba"},"source":["len(imagePaths)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3833"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ta1VV-5sRWQS","outputId":"266f74d0-ca00-488e-9897-d6b4ae3f6a90"},"source":["data = [] #our x\r\n","labels = [] #our y\r\n","\r\n","for i in imagePaths:\r\n","  label=i.split(os.path.sep)[-2]\r\n","  labels.append(label)\r\n","  image=load_img(i,target_size=(224,224)) #loaded image with all having size 224\r\n","  image=img_to_array(image) #converting images into array\r\n","  image=preprocess_input(image) #preprocessing images acc to mobilenet\r\n","  data.append(image)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"KhVEBTpAaI5k"},"source":["labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wuj17--eVb52"},"source":["data #x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qnMq9RX3Vc1A"},"source":["#converting data and labels into numpy array; they were in list so we converted them into array\r\n","data=np.array(data,dtype='float32')\r\n","labels=np.array(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1MG3AZivgnx1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612081338139,"user_tz":-330,"elapsed":1089,"user":{"displayName":"Siya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOgjn8zFSPn3wjONE5ghQ8g-5T-vg_1E4Zs9ZBOA=s64","userId":"12174409055975084288"}},"outputId":"6d994520-1d67-4b1b-965b-4c051a5b1868"},"source":["data.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3833, 224, 224, 3)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"QBoL6-GKV0vS"},"source":["data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Z9JRr03V13u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612081344436,"user_tz":-330,"elapsed":1150,"user":{"displayName":"Siya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOgjn8zFSPn3wjONE5ghQ8g-5T-vg_1E4Zs9ZBOA=s64","userId":"12174409055975084288"}},"outputId":"5e3c7a0f-68d3-43c0-b324-632a9ff4a9e3"},"source":["labels"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['with_mask', 'with_mask', 'with_mask', ..., 'without_mask',\n","       'without_mask', 'without_mask'], dtype='<U12')"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"goWNuQDlWIsX"},"source":["lb=LabelBinarizer()\r\n","labels=lb.fit_transform(labels)\r\n","labels=to_categorical(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zEjuXMsYWhMI"},"source":["labels #now model can understand this"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tWv8KNnRWiQT"},"source":["#split into training and testing\r\n","train_X,test_X,train_y,test_y = train_test_split(data,labels,test_size=0.20,random_state=10,stratify=labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vz54_pM9Xsrg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612081374896,"user_tz":-330,"elapsed":1064,"user":{"displayName":"Siya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOgjn8zFSPn3wjONE5ghQ8g-5T-vg_1E4Zs9ZBOA=s64","userId":"12174409055975084288"}},"outputId":"7def12c2-c56d-458a-f46f-776d2b8c411f"},"source":["train_X.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3066, 224, 224, 3)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"i6bKy_fohT0u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612081376195,"user_tz":-330,"elapsed":690,"user":{"displayName":"Siya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOgjn8zFSPn3wjONE5ghQ8g-5T-vg_1E4Zs9ZBOA=s64","userId":"12174409055975084288"}},"outputId":"48ddbe42-bbf3-4498-efa7-492e2dc4bb39"},"source":["train_y.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3066, 2)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"IDKGx7iGh8Hd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612081377746,"user_tz":-330,"elapsed":714,"user":{"displayName":"Siya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOgjn8zFSPn3wjONE5ghQ8g-5T-vg_1E4Zs9ZBOA=s64","userId":"12174409055975084288"}},"outputId":"6bdad8bc-e0ba-4ef1-9a22-a0efe0cd26e7"},"source":["test_X.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(767, 224, 224, 3)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"xfEILQqyiSAE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612081379388,"user_tz":-330,"elapsed":1084,"user":{"displayName":"Siya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOgjn8zFSPn3wjONE5ghQ8g-5T-vg_1E4Zs9ZBOA=s64","userId":"12174409055975084288"}},"outputId":"9f87cb64-d64d-4e8d-ab10-d2723c3c98cf"},"source":["test_y.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(767, 2)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"hvk6waBqiYqN"},"source":["#generating more number of images;  basically make 6-7 images from 1 image by rotating it and other things\r\n","\r\n","aug=ImageDataGenerator(rotation_range=20, zoom_range=0.15,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.15,horizontal_flip=True,vertical_flip=True,fill_mode='nearest')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T5udbkOLjawr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612081390507,"user_tz":-330,"elapsed":7871,"user":{"displayName":"Siya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOgjn8zFSPn3wjONE5ghQ8g-5T-vg_1E4Zs9ZBOA=s64","userId":"12174409055975084288"}},"outputId":"3701e341-4190-481b-a861-42af2b0bb5a7"},"source":["#CNN\r\n","\r\n","baseModel=MobileNetV2(weights='imagenet',include_top=False,input_tensor=Input(shape=(224,224,3)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kBYLIa2amLOd"},"source":["baseModel.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v8rPMcN7nyml"},"source":["headModel=baseModel.output\r\n","headModel=AveragePooling2D(pool_size=(7,7))(headModel)\r\n","headModel=Flatten(name='Flatten')(headModel)\r\n","headModel=Dense(128,activation='relu')(headModel)\r\n","headModel=Dense(32,activation='relu')(headModel)\r\n","headModel=Dropout(0.5)(headModel)\r\n","headModel=Dense(2,activation='softmax')(headModel)\r\n","\r\n","model=Model(inputs=baseModel.input,outputs=headModel)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WEkZc50psQFC"},"source":["for layer in baseModel.layers:\r\n","  layer.trainable=False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qt0D4lbVrzTp"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IbdyMrnri_g3","executionInfo":{"status":"ok","timestamp":1612081755213,"user_tz":-330,"elapsed":1097,"user":{"displayName":"Siya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOgjn8zFSPn3wjONE5ghQ8g-5T-vg_1E4Zs9ZBOA=s64","userId":"12174409055975084288"}},"outputId":"3f724f0e-88cc-47f6-cf3d-993874046fb5"},"source":["labels.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3833, 2)"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"iWsOtNTxr_ty","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612082383965,"user_tz":-330,"elapsed":628165,"user":{"displayName":"Siya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOgjn8zFSPn3wjONE5ghQ8g-5T-vg_1E4Zs9ZBOA=s64","userId":"12174409055975084288"}},"outputId":"895c92fa-a6af-4809-b4f3-803ed93ff8b6"},"source":["learning_rate=0.0001\r\n","Epochs=20\r\n","BS=12\r\n","\r\n","opt=Adam(lr=learning_rate,decay=learning_rate/Epochs)\r\n","model.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy'])\r\n","\r\n","H=model.fit(\r\n","    aug.flow(train_X,train_y,batch_size=BS),\r\n","    steps_per_epoch=len(train_X)//BS,\r\n","    validation_data=(test_X,test_y),\r\n","    validation_steps=len(test_X)//BS,\r\n","    epochs=Epochs\r\n",")\r\n","\r\n","model.save('/content/drive/MyDrive/mask1_mobilnet_v2.model')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","255/255 [==============================] - ETA: 0s - loss: 0.5392 - accuracy: 0.7419WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 63 batches). You may need to use the repeat() function when building your dataset.\n","255/255 [==============================] - 34s 127ms/step - loss: 0.5387 - accuracy: 0.7422 - val_loss: 0.1614 - val_accuracy: 0.9752\n","Epoch 2/20\n","255/255 [==============================] - 30s 120ms/step - loss: 0.2638 - accuracy: 0.9170\n","Epoch 3/20\n","255/255 [==============================] - 30s 119ms/step - loss: 0.1909 - accuracy: 0.9553\n","Epoch 4/20\n","255/255 [==============================] - 31s 120ms/step - loss: 0.1440 - accuracy: 0.9653\n","Epoch 5/20\n","255/255 [==============================] - 30s 119ms/step - loss: 0.1212 - accuracy: 0.9691\n","Epoch 6/20\n","255/255 [==============================] - 30s 119ms/step - loss: 0.0937 - accuracy: 0.9826\n","Epoch 7/20\n","255/255 [==============================] - 31s 121ms/step - loss: 0.1016 - accuracy: 0.9718\n","Epoch 8/20\n","255/255 [==============================] - 31s 121ms/step - loss: 0.0940 - accuracy: 0.9774\n","Epoch 9/20\n","255/255 [==============================] - 30s 119ms/step - loss: 0.0871 - accuracy: 0.9815\n","Epoch 10/20\n","255/255 [==============================] - 30s 119ms/step - loss: 0.0718 - accuracy: 0.9799\n","Epoch 11/20\n","255/255 [==============================] - 30s 118ms/step - loss: 0.0789 - accuracy: 0.9821\n","Epoch 12/20\n","255/255 [==============================] - 30s 118ms/step - loss: 0.0693 - accuracy: 0.9843\n","Epoch 13/20\n","255/255 [==============================] - 30s 117ms/step - loss: 0.0559 - accuracy: 0.9880\n","Epoch 14/20\n","255/255 [==============================] - 30s 117ms/step - loss: 0.0750 - accuracy: 0.9799\n","Epoch 15/20\n","255/255 [==============================] - 30s 118ms/step - loss: 0.0484 - accuracy: 0.9910\n","Epoch 16/20\n","255/255 [==============================] - 30s 117ms/step - loss: 0.0767 - accuracy: 0.9787\n","Epoch 17/20\n","255/255 [==============================] - 30s 118ms/step - loss: 0.0616 - accuracy: 0.9845\n","Epoch 18/20\n","255/255 [==============================] - 30s 118ms/step - loss: 0.0584 - accuracy: 0.9864\n","Epoch 19/20\n","255/255 [==============================] - 30s 117ms/step - loss: 0.0613 - accuracy: 0.9883\n","Epoch 20/20\n","255/255 [==============================] - 30s 118ms/step - loss: 0.0575 - accuracy: 0.9837\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/mask1_mobilnet_v2.model/assets\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ns9zXGQHua-2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612082462224,"user_tz":-330,"elapsed":2670,"user":{"displayName":"Siya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgOgjn8zFSPn3wjONE5ghQ8g-5T-vg_1E4Zs9ZBOA=s64","userId":"12174409055975084288"}},"outputId":"1595b994-195a-4b8b-d91d-4b46aac5d0d5"},"source":["predict=model.predict(test_X,batch_size=BS)\r\n","predict=np.argmax(predict,axis=1)\r\n","print(classification_report(test_y.argmax(axis=1),predict,target_names=lb.classes_))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","   with_mask       0.96      0.99      0.98       383\n","without_mask       0.99      0.96      0.98       384\n","\n","    accuracy                           0.98       767\n","   macro avg       0.98      0.98      0.98       767\n","weighted avg       0.98      0.98      0.98       767\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"drRTKGmFyRAJ"},"source":[""],"execution_count":null,"outputs":[]}]}